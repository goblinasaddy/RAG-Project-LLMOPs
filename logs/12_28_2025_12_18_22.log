{"timestamp": "2025-12-28T06:52:00.202771Z", "level": "info", "event": "Running in LOCAL mode: .env loaded"}
{"timestamp": "2025-12-28T06:52:00.206502Z", "level": "info", "event": "Loaded GOOGLE_API_KEY from individual env var"}
{"keys": {"GOOGLE_API_KEY": "AIzaSy..."}, "timestamp": "2025-12-28T06:52:00.208957Z", "level": "info", "event": "API keys loaded"}
{"config_keys": ["embedding_model", "retriever", "llm"], "timestamp": "2025-12-28T06:52:00.236826Z", "level": "info", "event": "YAML config loaded"}
{"session_id": "session_20251228_122200_415c8d7f", "temp_dir": "data\\session_20251228_122200_415c8d7f", "faiss_dir": "faiss_index\\session_20251228_122200_415c8d7f", "sessionized": true, "timestamp": "2025-12-28T06:52:00.245311Z", "level": "info", "event": "ChatIngestor initialized"}
{"uploaded": "AIAYN.pdf", "saved_as": "data\\session_20251228_122200_415c8d7f\\d00af4f0.pdf", "timestamp": "2025-12-28T06:52:00.251722Z", "level": "info", "event": "File saved for ingestion"}
{"count": 15, "timestamp": "2025-12-28T06:52:03.102501Z", "level": "info", "event": "Documents loaded"}
{"chunks": 52, "chunk_size": 1000, "overlap": 200, "timestamp": "2025-12-28T06:52:03.108813Z", "level": "info", "event": "Documents split"}
{"model": "models/text-embedding-004", "timestamp": "2025-12-28T06:52:03.117173Z", "level": "info", "event": "Loading embedding model"}
Loading faiss with AVX2 support.
Successfully loaded faiss with AVX2 support.
{"added": 1, "index": "faiss_index\\session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:52:06.029824Z", "level": "info", "event": "FAISS index updated"}
{"k": 5, "fetch_k": 20, "lambda_mult": 0.5, "timestamp": "2025-12-28T06:52:06.031113Z", "level": "info", "event": "Using MMR search"}
{"timestamp": "2025-12-28T06:52:26.558773Z", "level": "info", "event": "Running in LOCAL mode: .env loaded"}
{"timestamp": "2025-12-28T06:52:26.558773Z", "level": "info", "event": "Loaded GOOGLE_API_KEY from individual env var"}
{"keys": {"GOOGLE_API_KEY": "AIzaSy..."}, "timestamp": "2025-12-28T06:52:26.558773Z", "level": "info", "event": "API keys loaded"}
{"config_keys": ["embedding_model", "retriever", "llm"], "timestamp": "2025-12-28T06:52:26.564493Z", "level": "info", "event": "YAML config loaded"}
{"provider": "google", "model": "gemini-2.5-flash", "timestamp": "2025-12-28T06:52:26.564493Z", "level": "info", "event": "Loading LLM"}
{"session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:52:26.606378Z", "level": "info", "event": "LLM loaded successfully"}
{"session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:52:26.609626Z", "level": "info", "event": "ConversationalRAG initialized"}
{"timestamp": "2025-12-28T06:52:26.615036Z", "level": "info", "event": "Running in LOCAL mode: .env loaded"}
{"timestamp": "2025-12-28T06:52:26.615688Z", "level": "info", "event": "Loaded GOOGLE_API_KEY from individual env var"}
{"keys": {"GOOGLE_API_KEY": "AIzaSy..."}, "timestamp": "2025-12-28T06:52:26.615688Z", "level": "info", "event": "API keys loaded"}
{"config_keys": ["embedding_model", "retriever", "llm"], "timestamp": "2025-12-28T06:52:26.621154Z", "level": "info", "event": "YAML config loaded"}
{"model": "models/text-embedding-004", "timestamp": "2025-12-28T06:52:26.621154Z", "level": "info", "event": "Loading embedding model"}
{"session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:52:26.659732Z", "level": "info", "event": "LCEL graph built successfully"}
{"index_path": "faiss_index/session_20251228_122200_415c8d7f", "index_name": "index", "search_type": "mmr", "k": 5, "fetch_k": 20, "lambda_mult": 0.5, "session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:52:26.661348Z", "level": "info", "event": "FAISS retriever loaded successfully"}
{"session_id": "session_20251228_122200_415c8d7f", "user_input": "What is the name of the paper", "answer_preview": "The name of the paper is \"Attention Is All You Need.\"", "timestamp": "2025-12-28T06:52:38.541682Z", "level": "info", "event": "Chain invoked successfully"}
{"timestamp": "2025-12-28T06:53:12.339480Z", "level": "info", "event": "Running in LOCAL mode: .env loaded"}
{"timestamp": "2025-12-28T06:53:12.339480Z", "level": "info", "event": "Loaded GOOGLE_API_KEY from individual env var"}
{"keys": {"GOOGLE_API_KEY": "AIzaSy..."}, "timestamp": "2025-12-28T06:53:12.339480Z", "level": "info", "event": "API keys loaded"}
{"config_keys": ["embedding_model", "retriever", "llm"], "timestamp": "2025-12-28T06:53:12.347576Z", "level": "info", "event": "YAML config loaded"}
{"provider": "google", "model": "gemini-2.5-flash", "timestamp": "2025-12-28T06:53:12.347576Z", "level": "info", "event": "Loading LLM"}
{"session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:53:12.347576Z", "level": "info", "event": "LLM loaded successfully"}
{"session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:53:12.347576Z", "level": "info", "event": "ConversationalRAG initialized"}
{"timestamp": "2025-12-28T06:53:12.356032Z", "level": "info", "event": "Running in LOCAL mode: .env loaded"}
{"timestamp": "2025-12-28T06:53:12.356803Z", "level": "info", "event": "Loaded GOOGLE_API_KEY from individual env var"}
{"keys": {"GOOGLE_API_KEY": "AIzaSy..."}, "timestamp": "2025-12-28T06:53:12.357416Z", "level": "info", "event": "API keys loaded"}
{"config_keys": ["embedding_model", "retriever", "llm"], "timestamp": "2025-12-28T06:53:12.365066Z", "level": "info", "event": "YAML config loaded"}
{"model": "models/text-embedding-004", "timestamp": "2025-12-28T06:53:12.365066Z", "level": "info", "event": "Loading embedding model"}
{"session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:53:12.370960Z", "level": "info", "event": "LCEL graph built successfully"}
{"index_path": "faiss_index/session_20251228_122200_415c8d7f", "index_name": "index", "search_type": "mmr", "k": 5, "fetch_k": 20, "lambda_mult": 0.5, "session_id": "session_20251228_122200_415c8d7f", "timestamp": "2025-12-28T06:53:12.378577Z", "level": "info", "event": "FAISS retriever loaded successfully"}
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 47.538203901s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 47
}
].
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 44.993191368s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 44
}
].
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 40.414327135s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 40
}
].
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 31.885917238s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 31
}
].
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 15.357212095s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 15
}
].
{"error": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.771049425s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 20\n}\n, retry_delay {\n  seconds: 42\n}\n]", "timestamp": "2025-12-28T06:54:20.187197Z", "level": "error", "event": "Failed to invoke ConversationalRAG"}
